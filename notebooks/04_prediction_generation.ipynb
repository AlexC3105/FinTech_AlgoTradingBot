{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 04_prediction_generation.ipynb\n",
    "```markdown\n",
    "# 04_prediction_generation.ipynb\n",
    "\n",
    "## Notebook Purpose\n",
    "This notebook is designed to generate future price predictions using the trained machine learning models. It will load the trained models, apply them to the data, and save the predictions.\n",
    "\n",
    "## Instructions\n",
    "1. **Import Necessary Libraries**:\n",
    "   - Import `pandas` for data manipulation.\n",
    "   - Import `joblib` to load the trained model.\n",
    "   - Import functions from `models.py` for making predictions.\n",
    "\n",
    "2. **Load Preprocessed Data and Model**:\n",
    "   - Load the preprocessed CSV file created in the first notebook.\n",
    "   - Load the trained model from the previous notebook.\n",
    "\n",
    "3. **Generate Predictions**:\n",
    "   - Use the `make_prediction` function to generate predictions based on the trained model.\n",
    "   - Apply the model to the data to predict future prices.\n",
    "\n",
    "4. **Save Predictions**:\n",
    "   - Save the generated predictions to a new CSV file.\n",
    "\n",
    "5. **Review Predictions**:\n",
    "   - Display the first few rows of the predictions to ensure they look correct.\n",
    "\n",
    "## Example Code\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from scripts.models import make_prediction\n",
    "\n",
    "# Load preprocessed data and model\n",
    "data_path = 'data/historical_data/btc_usd_preprocessed.csv'  # Update this path based on the selected cryptocurrency\n",
    "data = pd.read_csv(data_path, parse_dates=['Date'], index_col='Date')\n",
    "model = joblib.load('models/trained_model.pkl')\n",
    "\n",
    "# Make predictions\n",
    "predictions = make_prediction(model, data)\n",
    "\n",
    "# Save predictions\n",
    "results = data[['Close']].copy()\n",
    "results['Predictions'] = predictions\n",
    "results.to_csv('results/predictions.csv')\n",
    "\n",
    "# Display predictions\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from ../models/BTC_random_forest_model.pkl.\n",
      "Model loaded successfully from ../models/ETH_random_forest_model.pkl.\n",
      "Model loaded successfully from ../models/SOL_random_forest_model.pkl.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Trained Models\n",
    "cryptos = [\"BTC\", \"ETH\", \"SOL\"]\n",
    "models = {}\n",
    "\n",
    "for crypto in cryptos:\n",
    "    model_path = f\"../models/{crypto}_random_forest_model.pkl\"\n",
    "    try:\n",
    "        models[crypto] = joblib.load(model_path)\n",
    "        print(f\"Model loaded successfully from {model_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model for {crypto}. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ../data/cleaned_data/BTC_cleaned.csv.\n",
      "Data loaded successfully from ../data/cleaned_data/ETH_cleaned.csv.\n",
      "Data loaded successfully from ../data/cleaned_data/SOL_cleaned.csv.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Data for Predictions\n",
    "crypto_data = {}\n",
    "\n",
    "for crypto in cryptos:\n",
    "    data_path = f'../data/cleaned_data/{crypto}_cleaned.csv'\n",
    "    try:\n",
    "        data = pd.read_csv(data_path, parse_dates=['date'], index_col='date')\n",
    "        crypto_data[crypto] = data\n",
    "        print(f\"Data loaded successfully from {data_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data for {crypto}. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing features for BTC: ['SMA_20', 'SMA_50', 'EMA_20', 'EMA_50', 'Return', 'Volatility']\n",
      "Missing features for ETH: ['SMA_20', 'SMA_50', 'EMA_20', 'EMA_50', 'Return', 'Volatility']\n",
      "Missing features for SOL: ['SMA_20', 'SMA_50', 'EMA_20', 'EMA_50', 'Return', 'Volatility']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Generate Predictions\n",
    "predictions = {}\n",
    "\n",
    "for crypto, model in models.items():\n",
    "    data = crypto_data[crypto]\n",
    "    features = ['open', 'high', 'low', 'volume', 'SMA_20', 'SMA_50', 'EMA_20', 'EMA_50', 'Return', 'Volatility']\n",
    "    \n",
    "    # Ensure the data has the expected columns\n",
    "    if all(feature in data.columns for feature in features):\n",
    "        X = data[features]\n",
    "        y_pred = model.predict(X)\n",
    "        predictions[crypto] = pd.DataFrame({\n",
    "            'date': data.index,\n",
    "            'predicted_close': y_pred\n",
    "        })\n",
    "        print(f\"Predictions generated for {crypto}.\")\n",
    "    else:\n",
    "        missing_features = [feature for feature in features if feature not in data.columns]\n",
    "        print(f\"Missing features for {crypto}: {missing_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
