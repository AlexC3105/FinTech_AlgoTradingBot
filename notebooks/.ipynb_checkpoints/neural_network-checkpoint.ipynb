{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06c4c85",
   "metadata": {},
   "source": [
    "# neural_network-checkpoint.ipynb\n",
    "\n",
    "## Notebook Purpose\n",
    "This notebook is designed to build, train, and evaluate a neural network model for predicting cryptocurrency prices. The model will be trained using the preprocessed historical data and will make future price predictions.\n",
    "\n",
    "## Instructions\n",
    "1. **Import Necessary Libraries**:\n",
    "   - Import `pandas` for data manipulation.\n",
    "   - Import necessary modules from `scikit-learn` and `tensorflow` for building and training the neural network.\n",
    "\n",
    "2. **Load Preprocessed Data**:\n",
    "   - Load the preprocessed CSV file containing the historical cryptocurrency data.\n",
    "\n",
    "3. **Build Neural Network Model**:\n",
    "   - Define and compile the neural network model using `Keras`.\n",
    "\n",
    "4. **Train the Model**:\n",
    "   - Split the data into training and testing sets.\n",
    "   - Train the model using the training data.\n",
    "\n",
    "5. **Evaluate Model Performance**:\n",
    "   - Evaluate the model using the testing data.\n",
    "   - Print the training and testing loss.\n",
    "\n",
    "6. **Make Predictions**:\n",
    "   - Use the trained model to make future price predictions.\n",
    "   - Save the predictions to a CSV file.\n",
    "\n",
    "## Example Code\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load preprocessed data\n",
    "data_path = 'data/historical_data/btc_usd_preprocessed.csv'\n",
    "data = pd.read_csv(data_path, parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Build and compile neural network model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(60, 1)))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['Close']], data[['Close']], test_size=0.2, shuffle=False)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "train_loss = model.evaluate(X_train_scaled, y_train)\n",
    "test_loss = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Make future predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "results = pd.DataFrame({'Date': X_test.index, 'Actual': y_test.values.flatten(), 'Predicted': predictions.flatten()})\n",
    "results.to_csv('results/nn_predictions.csv')\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(results['Date'], results['Actual'], label='Actual')\n",
    "plt.plot(results['Date'], results['Predicted'], label='Predicted')\n",
    "plt.title('Neural Network Predictions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load preprocessed data\n",
    "data_path = '../data/cleaned_data/BTC_cleaned.csv'  # Update this path based on the selected cryptocurrency\n",
    "data = pd.read_csv(data_path, parse_dates=['time'], index_col='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405830b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length), 0]\n",
    "        y = data[i+seq_length, 0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b714662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Extract closing prices and scale data\n",
    "close = data['close'].values.reshape(-1,1)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_close = scaler.fit_transform(close)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52285f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create sequences based on number of days\n",
    "seq_length = 60\n",
    "X, y = create_sequences(scaled_close, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Split data into training and testing sets\n",
    "split = int(len(X) * .80)\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Reshape data for LSTM input [samples, time steps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Build and compile LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ef07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Print model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3bec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a547c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Evaluate the model\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1311081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Predict using historic data (backtest)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Inverse transform the predictions and actual values\n",
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7bde6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Compare predictions vs actual values\n",
    "for i in range(10):\n",
    "    print(f'Predicted: {y_pred[-(10-i)][0]:.2f}, Actual: {y_test_inv[-(10-i)][0]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d12a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Predict the future\n",
    "X_future = []\n",
    "start_index = len(scaled_close) - seq_length\n",
    "for i in range(start_index, start_index + 30):\n",
    "    seq = scaled_close[i-seq_length:i, 0]\n",
    "    X_future.append(seq)\n",
    "X_future = np.array(X_future)\n",
    "X_future = X_future.reshape((X_future.shape[0], X_future.shape[1], 1))\n",
    "nn_future_predictions = model.predict(X_future)\n",
    "nn_future_predictions = scaler.inverse_transform(nn_future_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb38cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Derive future dates\n",
    "last_date = data.index[-1]\n",
    "next_30_days = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30)\n",
    "nn_dates_future = next_30_days.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Plot predictions\n",
    "print(\"nn_future_predictions:\")\n",
    "print(nn_future_predictions)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['close'], label='Historical Prices')\n",
    "plt.plot(nn_dates_future, nn_future_predictions, label='Predicted Prices', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Historical and Predicted Stock Prices using LSTM Neural Network')\n",
    "plt.legend()\n",
    "plt.savefig('results/nn_predict.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935349f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
