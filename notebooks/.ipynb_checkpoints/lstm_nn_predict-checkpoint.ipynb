{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7955c7e",
   "metadata": {},
   "source": [
    "# lstm_nn_predict-checkpoint.ipynb\n",
    "\n",
    "## Notebook Purpose\n",
    "This notebook uses the trained LSTM model to predict cryptocurrency prices for future days. It loads the trained model and test data, generates predictions, and saves the predicted prices.\n",
    "\n",
    "## Instructions\n",
    "1. **Import Necessary Libraries**:\n",
    "   - Import `pandas` for data manipulation.\n",
    "   - Import `joblib` to load the trained model.\n",
    "   - Import `MinMaxScaler` from `sklearn` for data normalization.\n",
    "   - Import `matplotlib` for visualization.\n",
    "\n",
    "2. **Load Test Data and Model**:\n",
    "   - Load the test data and the trained LSTM model.\n",
    "\n",
    "3. **Generate Predictions**:\n",
    "   - Use the model to predict future prices for 1, 3, 5, 7, 14, 21, and 30 days.\n",
    "\n",
    "4. **Save Predictions**:\n",
    "   - Save the generated predictions to a CSV file.\n",
    "\n",
    "5. **Review Predictions**:\n",
    "   - Display the predictions to verify they are as expected.\n",
    "\n",
    "## Example Code\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load test data and model\n",
    "data_path = 'data/historical_data/btc_usd_test.csv'  # Update this path based on the selected cryptocurrency\n",
    "data = pd.read_csv(data_path, parse_dates=['Date'], index_col='Date')\n",
    "model = joblib.load('models/trained_lstm_model.pkl')\n",
    "\n",
    "# Generate predictions\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[['Close']])\n",
    "future_predictions = model.predict(scaled_data)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "future_predictions = scaler.inverse_transform(future_predictions)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame(future_predictions, index=data.index, columns=['Predicted'])\n",
    "predictions_df.to_csv('results/lstm_nn_predictions.csv')\n",
    "\n",
    "# Display predictions\n",
    "predictions_df.head()\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, data['Close'], label='Actual Prices')\n",
    "plt.plot(predictions_df.index, predictions_df['Predicted'], label='Predicted Prices')\n",
    "plt.title('LSTM Model Predictions vs Actual Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries and set working directory\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define global variables\n",
    "global crypto_data, nn_models, nn_future_predictions\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Change to the root directory of the project\n",
    "os.chdir('../../')\n",
    "print(\"Changed working directory to:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b72b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load preprocessed data and models\n",
    "cryptos = ['BTC', 'ETH', 'SOL']\n",
    "crypto_data = {}\n",
    "nn_models = {}\n",
    "\n",
    "data_dir = 'data/cleaned_data'\n",
    "model_dir = 'models'\n",
    "\n",
    "# Print files in the directories to verify their presence\n",
    "print(f\"Files in {data_dir} directory: {os.listdir(data_dir)}\")\n",
    "print(f\"Files in {model_dir} directory: {os.listdir(model_dir)}\")\n",
    "\n",
    "for crypto in cryptos:\n",
    "    # Paths to data, model, and scaler\n",
    "    data_path = os.path.join(data_dir, f\"{crypto}_cleaned.csv\")\n",
    "    model_path = os.path.join(model_dir, f\"{crypto}_lstm_model.h5\")\n",
    "    scaler_path = os.path.join(model_dir, f\"{crypto}_scaler.pkl\")\n",
    "    \n",
    "    if os.path.exists(data_path) and os.path.exists(model_path) and os.path.exists(scaler_path):\n",
    "        crypto_data[crypto] = pd.read_csv(data_path, index_col='Date', parse_dates=True)\n",
    "        nn_models[crypto] = load_model(model_path)\n",
    "        \n",
    "        # Load scaler correctly\n",
    "        crypto_data[crypto]['scaler'] = joblib.load(scaler_path)\n",
    "        \n",
    "        # Verify the scaler type\n",
    "        scaler = crypto_data[crypto]['scaler']\n",
    "        if isinstance(scaler, MinMaxScaler):\n",
    "            print(f\"Scaler for {crypto} is a MinMaxScaler object\")\n",
    "        else:\n",
    "            print(f\"Scaler for {crypto} is not a MinMaxScaler object\")\n",
    "        \n",
    "        print(f\"{crypto} data and model loaded successfully\")\n",
    "    else:\n",
    "        print(f\"File not found: {data_path} or {model_path} or {scaler_path}\")\n",
    "\n",
    "if not crypto_data:\n",
    "    raise FileNotFoundError(\"No cryptocurrency data or models found. Please ensure data preparation and model training steps are completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49263044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Preprocess data and generate predictions\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length), 0]\n",
    "        y = data[i+seq_length, 0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "for crypto, df in crypto_data.items():\n",
    "    scaler = crypto_data[crypto]['scaler']\n",
    "    close_values = df[['Close']].values  # Use double brackets to ensure 2D array\n",
    "    scaled_data = scaler.transform(close_values)  # Using transform to ensure scaling\n",
    "\n",
    "    seq_length = 60\n",
    "    X, y = create_sequences(scaled_data, seq_length)\n",
    "    split = int(len(X) * .80)\n",
    "    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    crypto_data[crypto] = {\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'scaler': scaler,\n",
    "        'scaled_close': scaled_data\n",
    "    }\n",
    "\n",
    "print(\"Data preprocessing and sequence generation completed for all cryptocurrencies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cddefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define and train LSTM models\n",
    "nn_models = {}\n",
    "\n",
    "for crypto, data in crypto_data.items():\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "    \n",
    "    # Define the LSTM model with 50 neurons\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "    nn_model.add(Dense(units=1))\n",
    "    \n",
    "    # Compile the model\n",
    "    nn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Print the model summary\n",
    "    print(f\"{crypto} LSTM model summary:\")\n",
    "    print(nn_model.summary())\n",
    "    \n",
    "    # Train the model\n",
    "    nn_model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "    \n",
    "    nn_models[crypto] = nn_model\n",
    "\n",
    "print(\"Models trained for all cryptocurrencies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce1260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Evaluate the LSTM models\n",
    "for crypto, model in nn_models.items():\n",
    "    X_train = crypto_data[crypto]['X_train']\n",
    "    y_train = crypto_data[crypto]['y_train']\n",
    "    X_test = crypto_data[crypto]['X_test']\n",
    "    y_test = crypto_data[crypto]['y_test']\n",
    "    \n",
    "    nn_train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "    nn_test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    print(f'{crypto} - Train Loss: {nn_train_loss:.4f}, Test Loss: {nn_test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Predict using historical data (backtest)\n",
    "for crypto, model in nn_models.items():\n",
    "    X_test = crypto_data[crypto]['X_test']\n",
    "    scaler = crypto_data[crypto]['scaler']\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    y_test_inv = scaler.inverse_transform(crypto_data[crypto]['y_test'].reshape(-1, 1))\n",
    "    \n",
    "    # Compare predictions vs actual values\n",
    "    print(f\"{crypto} - Predictions vs Actual values:\")\n",
    "    for i in range(10):\n",
    "        print(f'Predicted: {y_pred[-(10-i)][0]:.2f}, Actual: {y_test_inv[-(10-i)][0]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab497bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Predict future prices\n",
    "nn_future_predictions = {}\n",
    "\n",
    "for crypto, model in nn_models.items():\n",
    "    scaled_close = crypto_data[crypto]['scaled_close']\n",
    "    scaler = crypto_data[crypto]['scaler']\n",
    "    \n",
    "    X_future = []\n",
    "    seq_length = 60\n",
    "    start_index = len(scaled_close) - seq_length\n",
    "    for i in range(start_index, start_index + 30):\n",
    "        seq = scaled_close[i-seq_length:i, 0]\n",
    "        X_future.append(seq)\n",
    "    \n",
    "    X_future = np.array(X_future)\n",
    "    X_future = np.reshape(X_future, (X_future.shape[0], X_future.shape[1], 1))\n",
    "    \n",
    "    future_predictions = model.predict(X_future)\n",
    "    future_predictions = scaler.inverse_transform(future_predictions)\n",
    "    \n",
    "    nn_future_predictions[crypto] = future_predictions\n",
    "\n",
    "print(\"Future predictions generated for all cryptocurrencies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de734b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot historical and predicted prices\n",
    "for crypto, future_predictions in nn_future_predictions.items():\n",
    "    original_df = pd.read_csv(f'data/cleaned_data/{crypto}_cleaned.csv', index_col='Date', parse_dates=True)\n",
    "    \n",
    "    last_date = original_df.index[-1]\n",
    "    next_30_days = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30)\n",
    "    nn_dates_future = next_30_days.values\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(original_df['Close'], label='Historical Prices')\n",
    "    plt.plot(nn_dates_future, future_predictions, label='Predicted Prices', linestyle='--')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Historical and Predicted Prices for {crypto} using LSTM Neural Network')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'results/output_predictions/{crypto}_nn_predict.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9fbaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
