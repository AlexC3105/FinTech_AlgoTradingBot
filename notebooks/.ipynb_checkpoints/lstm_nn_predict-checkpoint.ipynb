{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7955c7e",
   "metadata": {},
   "source": [
    "# lstm_nn_predict-checkpoint.ipynb\n",
    "\n",
    "## Notebook Purpose\n",
    "This notebook uses the trained LSTM model to predict cryptocurrency prices for future days. It loads the trained model and test data, generates predictions, and saves the predicted prices.\n",
    "\n",
    "## Instructions\n",
    "1. **Import Necessary Libraries**:\n",
    "   - Import `pandas` for data manipulation.\n",
    "   - Import `joblib` to load the trained model.\n",
    "   - Import `MinMaxScaler` from `sklearn` for data normalization.\n",
    "   - Import `matplotlib` for visualization.\n",
    "\n",
    "2. **Load Test Data and Model**:\n",
    "   - Load the test data and the trained LSTM model.\n",
    "\n",
    "3. **Generate Predictions**:\n",
    "   - Use the model to predict future prices for 1, 3, 5, 7, 14, 21, and 30 days.\n",
    "\n",
    "4. **Save Predictions**:\n",
    "   - Save the generated predictions to a CSV file.\n",
    "\n",
    "5. **Review Predictions**:\n",
    "   - Display the predictions to verify they are as expected.\n",
    "\n",
    "## Example Code\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load test data and model\n",
    "data_path = 'data/historical_data/btc_usd_test.csv'  # Update this path based on the selected cryptocurrency\n",
    "data = pd.read_csv(data_path, parse_dates=['Date'], index_col='Date')\n",
    "model = joblib.load('models/trained_lstm_model.pkl')\n",
    "\n",
    "# Generate predictions\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[['Close']])\n",
    "future_predictions = model.predict(scaled_data)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "future_predictions = scaler.inverse_transform(future_predictions)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame(future_predictions, index=data.index, columns=['Predicted'])\n",
    "predictions_df.to_csv('results/lstm_nn_predictions.csv')\n",
    "\n",
    "# Display predictions\n",
    "predictions_df.head()\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, data['Close'], label='Actual Prices')\n",
    "plt.plot(predictions_df.index, predictions_df['Predicted'], label='Predicted Prices')\n",
    "plt.title('LSTM Model Predictions vs Actual Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "global crypto_data\n",
    "global nn_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34cddefb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/cleaned_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Print files in the directories to verify their presence\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mlistdir(data_dir)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mlistdir(model_dir)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crypto \u001b[38;5;129;01min\u001b[39;00m cryptos:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/cleaned_data'"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load preprocessed data and models\n",
    "cryptos = ['BTC', 'ETH', 'SOL']\n",
    "crypto_data = {}\n",
    "nn_models = {}\n",
    "\n",
    "data_dir = '../data/cleaned_data'\n",
    "model_dir = '../models'\n",
    "\n",
    "# Print files in the directories to verify their presence\n",
    "print(f\"Files in {data_dir} directory: {os.listdir(data_dir)}\")\n",
    "print(f\"Files in {model_dir} directory: {os.listdir(model_dir)}\")\n",
    "\n",
    "for crypto in cryptos:\n",
    "    data_path = f'{data_dir}/{crypto}_cleaned.csv'\n",
    "    model_path = f'{model_dir}/{crypto}_lstm_model.h5'\n",
    "    scaler_path = f'{model_dir}/{crypto}_scaler.pkl'\n",
    "    \n",
    "    if os.path.exists(data_path) and os.path.exists(model_path) and os.path.exists(scaler_path):\n",
    "        crypto_data[crypto] = pd.read_csv(data_path, index_col='Date', parse_dates=True)\n",
    "        nn_models[crypto] = joblib.load(model_path)\n",
    "        crypto_data[crypto]['scaler'] = joblib.load(scaler_path)\n",
    "        \n",
    "        # Debugging: Verify scaler type\n",
    "        scaler = crypto_data[crypto]['scaler']\n",
    "        print(f\"{crypto} scaler type: {type(scaler)}\")\n",
    "        \n",
    "        print(f\"{crypto} data and model loaded successfully\")\n",
    "    else:\n",
    "        print(f\"File not found: {data_path} or {model_path} or {scaler_path}\")\n",
    "\n",
    "if not crypto_data:\n",
    "    raise FileNotFoundError(\"No cryptocurrency data or models found. Please ensure data preparation and model training steps are completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Preprocess data and generate predictions\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        x = data[i:(i + seq_length), 0]\n",
    "        y = data[i + seq_length, 0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "for crypto, df in crypto_data.items():\n",
    "    scaler = crypto_data[crypto]['scaler']\n",
    "    \n",
    "    # Ensure the scaler is of the correct type\n",
    "    if not isinstance(scaler, MinMaxScaler):\n",
    "        raise TypeError(f\"Scaler for {crypto} is not a MinMaxScaler object\")\n",
    "    \n",
    "    close_values = df['Close'].values.reshape(-1, 1)  # Ensure it's a 2D array for the scaler\n",
    "    scaled_data = scaler.transform(close_values)  # Using transform to ensure scaling\n",
    "    \n",
    "    seq_length = 60\n",
    "    X, y = create_sequences(scaled_data, seq_length)\n",
    "    split = int(len(X) * 0.80)\n",
    "    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "    \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    crypto_data[crypto].update({\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'scaled_data': scaled_data\n",
    "    })\n",
    "    \n",
    "    model = nn_models[crypto]\n",
    "    future_predictions = model.predict(X_test)\n",
    "    future_predictions = scaler.inverse_transform(future_predictions)\n",
    "    crypto_data[crypto]['future_predictions'] = future_predictions\n",
    "\n",
    "print(\"Predictions generated for all cryptocurrencies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab497bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load the trained LSTM model\n",
    "model_path = 'models/trained_lstm_model.pkl'  # Update this path based on the saved model\n",
    "nn_model = joblib.load(model_path)\n",
    "print(\"Trained LSTM model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de734b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Prepare the data for prediction\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[['Close']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Generate predictions for 1, 3, 5, 7, 14, 21, and 30 days\n",
    "prediction_days = [1, 3, 5, 7, 14, 21, 30]\n",
    "predictions = {}\n",
    "\n",
    "for days in prediction_days:\n",
    "    X_future = []\n",
    "    start_index = len(scaled_data) - days\n",
    "    for i in range(start_index, start_index + days):\n",
    "        seq = scaled_data[i - days:i, 0]\n",
    "        X_future.append(seq)\n",
    "    X_future = np.array(X_future)\n",
    "    X_future = np.reshape(X_future, (X_future.shape[0], X_future.shape[1], 1))\n",
    "    future_predictions = nn_model.predict(X_future)\n",
    "    future_predictions = scaler.inverse_transform(future_predictions)\n",
    "    predictions[days] = future_predictions\n",
    "    print(f\"Predictions for {days} days generated successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae5cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save predictions to CSV files\n",
    "for days, preds in predictions.items():\n",
    "    predictions_df = pd.DataFrame(preds, index=data.index[-days:], columns=['Predicted'])\n",
    "    predictions_df.to_csv(f'results/lstm_nn_predictions_{days}_days.csv')\n",
    "    print(f\"Predictions for {days} days saved to 'results/lstm_nn_predictions_{days}_days.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Display a sample of predictions\n",
    "sample_days = 5  # Number of sample days to display\n",
    "sample_predictions = predictions[sample_days]\n",
    "print(f\"Sample predictions for {sample_days} days:\")\n",
    "print(sample_predictions[:sample_days])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b10d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Plot predictions vs actual prices\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, data['Close'], label='Actual Prices')\n",
    "for days, preds in predictions.items():\n",
    "    plt.plot(data.index[-days:], preds, label=f'Predicted Prices ({days} days)')\n",
    "plt.title('LSTM Model Predictions vs Actual Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9fbaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
