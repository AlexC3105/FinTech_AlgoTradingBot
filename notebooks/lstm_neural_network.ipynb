{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b911349d",
   "metadata": {},
   "source": [
    "# lstm_neural_network.ipynb\n",
    "\n",
    "## Notebook Purpose\n",
    "This notebook is designed to develop and train an LSTM (Long Short-Term Memory) neural network model for predicting cryptocurrency prices. The trained LSTM model will be used to generate future price predictions.\n",
    "\n",
    "## Instructions\n",
    "1. **Import Necessary Libraries**:\n",
    "   - Import `pandas` and `numpy` for data manipulation.\n",
    "   - Import `MinMaxScaler` from `sklearn.preprocessing` for feature scaling.\n",
    "   - Import necessary modules from `tensorflow.keras` for building the LSTM model.\n",
    "\n",
    "2. **Load Preprocessed Data**:\n",
    "   - Load the preprocessed CSV file created in the first notebook.\n",
    "\n",
    "3. **Prepare Data for LSTM**:\n",
    "   - Scale the data using `MinMaxScaler`.\n",
    "   - Create sequences of data for LSTM input.\n",
    "\n",
    "4. **Build and Train LSTM Model**:\n",
    "   - Define the LSTM model architecture.\n",
    "   - Compile and train the model using the prepared data.\n",
    "\n",
    "5. **Save the Trained Model**:\n",
    "   - Save the trained LSTM model to a file for later use.\n",
    "\n",
    "6. **Evaluate Model Performance**:\n",
    "   - Evaluate the model's performance using appropriate metrics.\n",
    "\n",
    "## Example Code\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import joblib\n",
    "\n",
    "# Load preprocessed data\n",
    "data_path = 'data/historical_data/btc_usd_preprocessed.csv'  # Update this path based on the selected cryptocurrency\n",
    "data = pd.read_csv(data_path, parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Prepare data for LSTM\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        x = data[i:(i + seq_length), 0]\n",
    "        y = data[i + seq_length, 0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 60\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "X_train, X_test = X[:int(len(X) * 0.8)], X[int(len(X) * 0.8):]\n",
    "y_train, y_test = y[:int(len(y) * 0.8)], y[int(len(y) * 0.8):]\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dense(units=25))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=1, epochs=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('models/lstm_model.h5')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "\n",
    "# Evaluate model performance\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Train Loss: {train_loss:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996659a-4f6b-400b-85ae-d1828d3bb614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 1: Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5efcc-aaff-41c8-b74b-0c7cf76c2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Global variables\n",
    "global prices_df\n",
    "global nn_model\n",
    "global nn_future_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5266748-c3fd-46ce-ad13-f8f1617278c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: Print statement to indicate the start\n",
    "print(\"in neural network\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d9bdbb-f6f7-420f-b8b7-1bde7056ca4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Function to create sequences of data\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length), 0]\n",
    "        y = data[i+seq_length, 0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0fab0d-69a1-4f1e-a873-b8388a8391d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 5: Load data and extract closing prices\n",
    "prices_df = pd.read_csv('../data/cleaned_data/BTC_cleaned.csv', index_col='Date', parse_dates=True)  # Update this path based on the selected cryptocurrency\n",
    "close = prices_df['Close'].values.reshape(-1,1)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_close = scaler.fit_transform(close)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac1e82-7ad3-4481-beac-6cf9cc56740b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 6: Create sequences based on number of days\n",
    "seq_length = 60\n",
    "X, y = create_sequences(scaled_close, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ddf6d4-b9e7-44d9-93c0-15ff398b9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Split into training and testing data\n",
    "split = int(len(X) * .80)\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40818ebc-e892-453f-980a-99bdfa579003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Reshape data for LSTM input [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f93252-8056-401c-86e8-ed4044307f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Define the LSTM model with 50 neurons\n",
    "nn_model = Sequential()\n",
    "nn_model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "nn_model.add(Dense(units=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2f7a5-2082-4e23-b7db-dfc1045d0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Compile the model\n",
    "nn_model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de01004-147a-4d5f-8533-e1badbed9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Print the model summary\n",
    "print(nn_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da553e3-2b9c-4f0a-af22-b35795682eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 12: Train the model\n",
    "nn_model.fit(X_train, y_train, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11f294-26ac-4b2e-aa4a-613e09026988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Evaluate the model using the testing data\n",
    "nn_train_loss = nn_model.evaluate(X_train, y_train, verbose=0)\n",
    "nn_test_loss = nn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Train Loss: {nn_train_loss:.4f}')\n",
    "print(f'Test Loss: {nn_test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badfbebc-958e-4515-8992-27fde91ed5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Predict using Historic Data (Backtest)\n",
    "y_pred = nn_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1173738a-c197-4742-939d-2bc1c985a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Inverse transform the predictions (to get actual prices)\n",
    "y_pred = scaler.inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6d694-59fa-4d4f-b96f-8f1feb588884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Inverse transform the actual values for comparison\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e980e-34df-417c-8bc9-c65b82cddde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Compare predictions vs actual values\n",
    "for i in range(10):\n",
    "    print(f'Predicted: {y_pred[-(10-i)][0]:.2f}, Actual: {y_test_inv[-(10-i)][0]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac693358-f2af-408d-8f15-ab8982a55cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#recall seq_length = 60, set above\n",
    "# predict for 30 days\n",
    "X_future = []\n",
    "start_index = len(scaled_close) - seq_length\n",
    "for i in range(start_index, start_index + 30):\n",
    "    seq = scaled_close[i-seq_length:i,0]\n",
    "    X_future.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd570d20-74f4-4a0c-bc14-62f5e54a9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Predict the Future\n",
    "X_future = []\n",
    "start_index = len(scaled_close) - seq_length\n",
    "for i in range(start_index, start_index + 30):\n",
    "    seq = scaled_close[i-seq_length:i,0]\n",
    "    X_future.append(seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a7772-ec53-4be0-a60c-6979e6107a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Convert X_future to numpy array and reshape for LSTM input\n",
    "X_future = np.array(X_future)\n",
    "X_future = np.reshape(X_future, (X_future.shape[0], X_future.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29ad5a-4e4d-4886-9cad-e1c5ec37c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Predict future prices\n",
    "nn_future_predictions = nn_model.predict(X_future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e3d0a-81db-4270-8431-2e34cda4bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: Inverse transform the predictions to get actual prices\n",
    "nn_future_predictions = scaler.inverse_transform(nn_future_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251eba1-32a7-4e13-bd7d-cf6d7bb5dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: Derive future dates\n",
    "last_date = prices_df.index[-1]\n",
    "next_30_days = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30)\n",
    "nn_dates_future = next_30_days.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fc03f-c1e4-412d-9d20-fc26cd8120a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23: Print future predictions\n",
    "print(\"nn_future_predictions:\")\n",
    "print(nn_future_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13922259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: Plotting historical and predicted prices\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(prices_df['Close'], label='Historical Prices')\n",
    "plt.plot(nn_dates_future, nn_future_predictions, label='Predicted Prices', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Historical and Predicted Stock Prices using LSTM Neural Network')\n",
    "plt.legend()\n",
    "plt.savefig('nn_predict.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdaba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Save future predictions to the output_predictions folder\n",
    "output_path = '../results/output_predictions/BTC_future_predictions.csv'\n",
    "nn_future_predictions_df = pd.DataFrame({\n",
    "    'Date': nn_dates_future,\n",
    "    'Predicted Price': nn_future_predictions.flatten()\n",
    "})\n",
    "nn_future_predictions_df.to_csv(output_path, index=False)\n",
    "print(f\"Future predictions saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee682030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
