{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_data_preparation.ipynb\n",
    "\n",
    "## Notebook Purpose\n",
    "This notebook is designed to load, clean, and preprocess historical cryptocurrency data. It will also calculate technical indicators that will be used for further analysis and model training.\n",
    "\n",
    "## Instructions\n",
    "1. **Import Necessary Libraries**:\n",
    "   - Import `pandas` for data manipulation.\n",
    "   - Import functions from `utils.py` for loading, preprocessing data, and calculating technical indicators.\n",
    "\n",
    "2. **Load Data**:\n",
    "   - Use the `load_data` function to load the CSV file containing historical cryptocurrency data.\n",
    "\n",
    "3. **Preprocess Data**:\n",
    "   - Use the `preprocess_data` function to clean and preprocess the loaded data.\n",
    "   - Ensure any missing values are handled appropriately.\n",
    "\n",
    "4. **Calculate Technical Indicators**:\n",
    "   - Use the `calculate_indicators` function to add technical indicators (e.g., SMA, EMA, RSI) to the data.\n",
    "\n",
    "5. **Save Preprocessed Data**:\n",
    "   - Save the cleaned and preprocessed data, including the calculated technical indicators, to a new CSV file for later use.\n",
    "\n",
    "6. **Review Data**:\n",
    "   - Display the first few rows of the preprocessed data to ensure it looks correct.\n",
    "\n",
    "## Example Code\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from scripts.utils import load_data, preprocess_data, calculate_indicators\n",
    "\n",
    "# Load data\n",
    "data_path = 'data/historical_data/btc_usd.csv'  # Update this path based on the selected cryptocurrency\n",
    "data = load_data(data_path)\n",
    "\n",
    "# Preprocess data\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Calculate technical indicators\n",
    "data = calculate_indicators(data)\n",
    "\n",
    "# Save the preprocessed data\n",
    "data.to_csv('data/historical_data/btc_usd_preprocessed.csv')\n",
    "\n",
    "# Display the first few rows of the preprocessed data\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully. Let's proceed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import necessary libraries and verify\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import requests\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    import ccxt\n",
    "    %matplotlib inline\n",
    "    print(\"Libraries loaded successfully. Let's proceed!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Uh-oh! Please verify the installation of: {e.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Coinbase connection...\n",
      "Coinbase object created.\n",
      "Error during Coinbase connection test:\n",
      "index out of range\n",
      "Testing Alpha Vantage connection...\n",
      "Testing CryptoCompare connection...\n",
      "Coinbase: Failed to connect. Error: index out of range\n",
      "Alpha Vantage: Connection successful.\n",
      "CryptoCompare: Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load environment variables and fetch API keys\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import ccxt\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch API keys\n",
    "COINBASE_API_KEY = os.getenv(\"COINBASE_API_KEY\")\n",
    "COINBASE_API_SECRET = os.getenv(\"COINBASE_API_SECRET\")\n",
    "ALPHA_VANTAGE_API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "CRYPTOCOMPARE_API_KEY = os.getenv(\"CRYPTOCOMPARE_API_KEY\")\n",
    "\n",
    "# Function to test API connection for each service\n",
    "def test_api_connection():\n",
    "    report = []\n",
    "\n",
    "    # Test Coinbase API connection using ccxt\n",
    "    try:\n",
    "        print(\"Testing Coinbase connection...\")\n",
    "        coinbase = ccxt.coinbase({\n",
    "            'apiKey': COINBASE_API_KEY,\n",
    "            'secret': COINBASE_API_SECRET\n",
    "        })\n",
    "        print(\"Coinbase object created.\")\n",
    "        markets = coinbase.load_markets()\n",
    "        print(\"Coinbase markets loaded.\")\n",
    "        balance = coinbase.fetch_balance()\n",
    "        print(\"Coinbase balance fetched.\")\n",
    "        report.append(\"Coinbase: Connection successful.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error during Coinbase connection test:\")\n",
    "        print(e)\n",
    "        report.append(f\"Coinbase: Failed to connect. Error: {str(e)}\")\n",
    "    \n",
    "    # Test Alpha Vantage API connection\n",
    "    print(\"Testing Alpha Vantage connection...\")\n",
    "    if ALPHA_VANTAGE_API_KEY:\n",
    "        try:\n",
    "            response = requests.get(f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&apikey={ALPHA_VANTAGE_API_KEY}\")\n",
    "            if response.status_code == 200:\n",
    "                report.append(\"Alpha Vantage: Connection successful.\")\n",
    "            else:\n",
    "                report.append(f\"Alpha Vantage: Failed to connect. Status code: {response.status_code}, Message: {response.text}\")\n",
    "        except Exception as e:\n",
    "            report.append(f\"Alpha Vantage: Failed to connect. Error: {str(e)}\")\n",
    "    else:\n",
    "        report.append(\"Alpha Vantage: API key missing.\")\n",
    "    \n",
    "    # Test CryptoCompare API connection\n",
    "    print(\"Testing CryptoCompare connection...\")\n",
    "    if CRYPTOCOMPARE_API_KEY:\n",
    "        try:\n",
    "            response = requests.get(f\"https://min-api.cryptocompare.com/data/pricemulti?fsyms=BTC&tsyms=USD\", headers={\"authorization\": f\"Apikey {CRYPTOCOMPARE_API_KEY}\"})\n",
    "            if response.status_code == 200:\n",
    "                report.append(\"CryptoCompare: Connection successful.\")\n",
    "            else:\n",
    "                report.append(f\"CryptoCompare: Failed to connect. Status code: {response.status_code}, Message: {response.text}\")\n",
    "        except Exception as e:\n",
    "            report.append(f\"CryptoCompare: Failed to connect. Error: {str(e)}\")\n",
    "    else:\n",
    "        report.append(\"CryptoCompare: API key missing.\")\n",
    "    \n",
    "    # Print connection report\n",
    "    for line in report:\n",
    "        print(line)\n",
    "\n",
    "# Run the API connection test\n",
    "test_api_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Vantage Data Columns for BTC: Index(['date', '1. open', '2. high', '3. low', '4. close', 'volume'], dtype='object')\n",
      "Missing expected columns in Alpha Vantage data for BTC\n",
      "Alpha Vantage Data Columns for ETH: Index(['date', '1. open', '2. high', '3. low', '4. close', 'volume'], dtype='object')\n",
      "Missing expected columns in Alpha Vantage data for ETH\n",
      "Alpha Vantage Data Columns for SOL: Index(['date', '1. open', '2. high', '3. low', '4. close', 'volume'], dtype='object')\n",
      "Missing expected columns in Alpha Vantage data for SOL\n",
      "Creating Coinbase object for BTC...\n",
      "Coinbase object created.\n",
      "Failed to fetch data from Coinbase: index out of range\n",
      "Creating Coinbase object for ETH...\n",
      "Coinbase object created.\n",
      "Failed to fetch data from Coinbase: index out of range\n",
      "Creating Coinbase object for SOL...\n",
      "Coinbase object created.\n",
      "Failed to fetch data from Coinbase: index out of range\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Function to fetch historical data from APIs\n",
    "def fetch_api_data():\n",
    "    cryptos = [\"BTC\", \"ETH\", \"SOL\"]\n",
    "    api_data = {}\n",
    "\n",
    "    # Fetch data from Alpha Vantage\n",
    "    for crypto in cryptos:\n",
    "        alpha_vantage_data = fetch_alpha_vantage_data(crypto)\n",
    "        if alpha_vantage_data is not None:\n",
    "            api_data[f\"{crypto}_alpha_vantage\"] = alpha_vantage_data\n",
    "\n",
    "    # Fetch data from Coinbase\n",
    "    for crypto in cryptos:\n",
    "        coinbase_data = fetch_coinbase_data(crypto, '2018-01-01', '2023-12-31')\n",
    "        if coinbase_data is not None:\n",
    "            api_data[f\"{crypto}_coinbase\"] = coinbase_data\n",
    "\n",
    "    # Fetch data from CryptoCompare\n",
    "    for crypto in cryptos:\n",
    "        cryptocompare_data = fetch_cryptocompare_data(crypto, '2018-01-01', '2023-12-31')\n",
    "        if cryptocompare_data is not None:\n",
    "            api_data[f\"{crypto}_cryptocompare\"] = cryptocompare_data\n",
    "\n",
    "    return api_data\n",
    "\n",
    "# Fetch data from APIs\n",
    "api_data = fetch_api_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in BTC data: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "Manually downloaded data loaded for BTC.\n",
      "Columns in ETH data: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "Manually downloaded data loaded for ETH.\n",
      "Columns in SOL data: Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "Manually downloaded data loaded for SOL.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load manually downloaded data\n",
    "def load_manual_data(cryptos):\n",
    "    manual_data = {}\n",
    "    for crypto in cryptos:\n",
    "        try:\n",
    "            data_path = f'../data/historical_data/{crypto}-USD.csv'\n",
    "            df = pd.read_csv(data_path)\n",
    "            print(f\"Columns in {crypto} data: {df.columns}\")  # Debug print to show the column names\n",
    "            if 'Date' in df.columns:\n",
    "                df = pd.read_csv(data_path, parse_dates=['Date'])\n",
    "                df = df.rename(columns={'Date': 'time', 'Adj Close': 'adj_close', 'Volume': 'volume', 'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close'})\n",
    "            else:\n",
    "                raise ValueError(f\"No 'Date' column found in {crypto} data\")\n",
    "            df = df.set_index('time')\n",
    "            manual_data[crypto] = df\n",
    "            print(f\"Manually downloaded data loaded for {crypto}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading manually downloaded data for {crypto}: {str(e)}\")\n",
    "    return manual_data\n",
    "\n",
    "cryptos = [\"BTC\", \"ETH\", \"SOL\"]\n",
    "manual_data = load_manual_data(cryptos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Combine data sources\n",
    "def combine_data_sources(api_data, manual_data):\n",
    "    combined_data = {}\n",
    "    for crypto in [\"BTC\", \"ETH\", \"SOL\"]:\n",
    "        combined_df = pd.DataFrame()\n",
    "        for source, df in api_data.items():\n",
    "            if crypto in source:\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                combined_df = pd.concat([combined_df, df])\n",
    "        if crypto in manual_data:\n",
    "            manual_df = manual_data[crypto]\n",
    "            manual_df.index = pd.to_datetime(manual_df.index)\n",
    "            combined_df = pd.concat([combined_df, manual_df])\n",
    "        combined_df = combined_df.sort_index().drop_duplicates()\n",
    "        combined_data[crypto] = combined_df\n",
    "    return combined_data\n",
    "\n",
    "# Combine data\n",
    "combined_data = combine_data_sources(api_data, manual_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Preprocess the data\n",
    "def preprocess_data(data):\n",
    "    data = data.dropna()\n",
    "    data['SMA_20'] = data['close'].rolling(window=20).mean()\n",
    "    data['SMA_50'] = data['close'].rolling(window=50).mean()\n",
    "    data['EMA_20'] = data['close'].ewm(span=20, adjust=False).mean()\n",
    "    data['EMA_50'] = data['close'].ewm(span=50, adjust=False).mean()\n",
    "    data['Return'] = data['close'].pct_change()\n",
    "    data['Volatility'] = data['Return'].rolling(window=20).std()\n",
    "    return data.dropna()\n",
    "\n",
    "# Preprocess combined data\n",
    "preprocessed_data = {crypto: preprocess_data(df) for crypto, df in combined_data.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to ../data/cleaned_data/BTC_cleaned.csv\n",
      "Preprocessed data saved to ../data/cleaned_data/ETH_cleaned.csv\n",
      "Preprocessed data saved to ../data/cleaned_data/SOL_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save preprocessed data to CSV\n",
    "# Function to save preprocessed data to CSV files\n",
    "def save_preprocessed_data(preprocessed_data):\n",
    "    os.makedirs('../data/cleaned_data', exist_ok=True)\n",
    "    for crypto, df in preprocessed_data.items():\n",
    "        file_path = f\"../data/cleaned_data/{crypto}_cleaned.csv\"\n",
    "        df.to_csv(file_path)\n",
    "        print(f\"Preprocessed data saved to {file_path}\")\n",
    "\n",
    "# Save preprocessed data\n",
    "save_preprocessed_data(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BTC Preprocessed Data Head:\n",
      "                                    date     open     high      low    close  \\\n",
      "1970-01-01 00:00:00.000000000 2018-07-10  6668.84  6683.61  6277.23  6306.85   \n",
      "1970-01-01 00:00:00.000000001 2018-07-11  6306.87  6405.59  6293.68  6394.36   \n",
      "1970-01-01 00:00:00.000000002 2018-07-12  6394.36  6394.93  6084.00  6253.60   \n",
      "1970-01-01 00:00:00.000000003 2018-07-13  6253.66  6349.21  6131.54  6229.83   \n",
      "1970-01-01 00:00:00.000000004 2018-07-14  6229.61  6332.46  6190.18  6268.75   \n",
      "\n",
      "                                     volume  adj_close  \n",
      "1970-01-01 00:00:00.000000000  4.704321e+08        NaN  \n",
      "1970-01-01 00:00:00.000000001  3.276678e+08        NaN  \n",
      "1970-01-01 00:00:00.000000002  4.090782e+08        NaN  \n",
      "1970-01-01 00:00:00.000000003  3.198023e+08        NaN  \n",
      "1970-01-01 00:00:00.000000004  1.744168e+08        NaN  \n",
      "\n",
      "ETH Preprocessed Data Head:\n",
      "                                    date    open    high     low   close  \\\n",
      "1970-01-01 00:00:00.000000000 2018-07-10  471.48  473.06  427.82  432.69   \n",
      "1970-01-01 00:00:00.000000001 2018-07-11  432.69  447.09  425.13  445.59   \n",
      "1970-01-01 00:00:00.000000002 2018-07-12  445.94  439.25  430.12  431.12   \n",
      "1970-01-01 00:00:00.000000003 2018-07-13  431.13  438.52  429.42  432.97   \n",
      "1970-01-01 00:00:00.000000004 2018-07-14  432.96  438.69  433.73  434.42   \n",
      "\n",
      "                                     volume  adj_close  \n",
      "1970-01-01 00:00:00.000000000  2.505325e+08        NaN  \n",
      "1970-01-01 00:00:00.000000001  1.412303e+08        NaN  \n",
      "1970-01-01 00:00:00.000000002  3.046619e+08        NaN  \n",
      "1970-01-01 00:00:00.000000003  4.414171e+08        NaN  \n",
      "1970-01-01 00:00:00.000000004  4.278088e+08        NaN  \n",
      "\n",
      "SOL Preprocessed Data Head:\n",
      "                                    date  open  high  low  close  volume  \\\n",
      "1970-01-01 00:00:00.000000000 2018-07-10   0.0   0.0  0.0    0.0     0.0   \n",
      "1970-01-01 00:00:00.000000001 2018-07-11   0.0   0.0  0.0    0.0     0.0   \n",
      "1970-01-01 00:00:00.000000002 2018-07-12   0.0   0.0  0.0    0.0     0.0   \n",
      "1970-01-01 00:00:00.000000003 2018-07-13   0.0   0.0  0.0    0.0     0.0   \n",
      "1970-01-01 00:00:00.000000004 2018-07-14   0.0   0.0  0.0    0.0     0.0   \n",
      "\n",
      "                               adj_close  \n",
      "1970-01-01 00:00:00.000000000        NaN  \n",
      "1970-01-01 00:00:00.000000001        NaN  \n",
      "1970-01-01 00:00:00.000000002        NaN  \n",
      "1970-01-01 00:00:00.000000003        NaN  \n",
      "1970-01-01 00:00:00.000000004        NaN  \n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Verify the preprocessed data\n",
    "for crypto, df in combined_data.items():\n",
    "    print(f\"\\n{crypto} Preprocessed Data Head:\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
