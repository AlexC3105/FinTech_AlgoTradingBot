{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c5cb82-e5cf-4321-a616-7d1d4e235303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55cf4f4-359d-4738-9dd7-1ded55778284",
   "metadata": {},
   "outputs": [],
   "source": [
    "global prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daba935-6180-4e0e-8b44-902abb7c6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy prices since want to add features for random forest\n",
    "#Note: the code below for some reason generates a namerror message; however\n",
    "#code itself works, with rf_prices_df being copied from prices_df, so I'm assuming\n",
    "#it's a python environmental error\n",
    "rf_prices_df = prices_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62604de-397c-40a5-96ef-ddb4177e2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create features of lagging prices\n",
    "\n",
    "# Define number of lags\n",
    "num_lags = 7\n",
    "\n",
    "# Create lagged features (so \"close_lag1\" represents closing prices from previous day; \"close_lag2\" represents\n",
    "# prices from 2 days ago, etc.\n",
    "for i in range(1, num_lags + 1):\n",
    "    rf_prices_df[f'Close_Lag{i}'] = rf_prices_df['Close'].shift(i)\n",
    "\n",
    "# Drop rows with NaN values (first 7 rows in this case)\n",
    "rf_prices_df = rf_prices_df.dropna()\n",
    "\n",
    "# Split data into train and test sets - use all but the last 90 rows for training, \n",
    "# then use the last 90 rows for backtesting\n",
    "train_df = rf_prices_df.iloc[:-90]\n",
    "test_df = rf_prices_df.iloc[-90:]\n",
    "\n",
    "# Separate lagged features and target variable\n",
    "X_train = train_df[['Close_Lag1', 'Close_Lag2', 'Close_Lag3', 'Close_Lag4', 'Close_Lag5', 'Close_Lag6', 'Close_Lag7']]\n",
    "y_train = train_df['Close']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a6602-10a0-47a1-9020-525729b4ee03",
   "metadata": {},
   "source": [
    "## Create and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4950d3-3fb5-4f15-bdd1-503d2c7e5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model: 100 trees; \n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model using the historical training data\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89dad23-70b6-4484-90fe-320d5ad1d6d1",
   "metadata": {},
   "source": [
    "## Predict using Historic Data (Backtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a416c5-928f-4915-a3bb-d8d029aad7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate lagged features and target variable\n",
    "X_test = test_df[['Close_Lag1', 'Close_Lag2', 'Close_Lag3', 'Close_Lag4', 'Close_Lag5', 'Close_Lag6', 'Close_Lag7']]\n",
    "y_true = test_df['Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e889145-81a6-4288-b25f-8e770a36c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the last 90 days of the historical data\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5d1f4-fb0a-4685-aee2-144930777b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_true, predictions)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6716a592-a338-46ca-9d5a-23cf45cb17c8",
   "metadata": {},
   "source": [
    "## Predict the Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcb0d9-d683-4d9a-8e8e-98961882eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of days to predict into the future\n",
    "days_to_predict = 30\n",
    "\n",
    "# Generate future dates starting from the last known date in prices_df\n",
    "last_known_date = rf_prices_df.index[-1]\n",
    "rf_future_dates = pd.date_range(start=last_known_date + pd.Timedelta(days=1), periods=days_to_predict, freq='D')\n",
    "\n",
    "# Create a DataFrame for future predictions\n",
    "rf_future_df = pd.DataFrame(index=rf_future_dates)\n",
    "\n",
    "# Get the last 7 rows from the historical, to create new dataframe\n",
    "last7_df = rf_prices_df.tail(7)\n",
    "\n",
    "# Drop everything except Close\n",
    "last7_df = last7_df[\"Close\"]\n",
    "\n",
    "# Append to future - needed so we can calculate lag\n",
    "rf_future_df = pd.concat([last7_df, rf_future_df])\n",
    "\n",
    "# Name the column\n",
    "rf_future_df.columns =['Close']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e826a-608f-4e7c-97e6-b189758f722f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through future dates to predict stock prices\n",
    "# Need to calculate lag and predict at same time, since need\n",
    "# lag to calculate prices, but need prices to calculate lag\n",
    "      \n",
    "for date in rf_future_dates:\n",
    "    # Create lagged features for the current future date\n",
    "    lagged_features = []\n",
    "    for i in range(1, num_lags + 1):\n",
    "        index_position = rf_future_df.index.get_loc(date)\n",
    "        # Back up i rows\n",
    "        previous_index_position = index_position - i\n",
    "        # append that day's price\n",
    "        lagged_features.append(rf_future_df.loc[rf_future_df.index[previous_index_position], \"Close\"])\n",
    "    \n",
    "    # Predict stock price for the current future date using lagged features; predict returns\n",
    "    # an array, so get the first element (is also the only element, in this case)\n",
    "    prediction = rf_model.predict([lagged_features])[0]\n",
    " \n",
    "    # Add the predicted price to future_df\n",
    "    rf_future_df.loc[date, 'Close'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9874d6-6cc3-4054-90cb-5695085364c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up rf_future_dt:\n",
    "\n",
    "# Drop the first 7 rows, to get rid of the historical data\n",
    "rf_future_df = rf_future_df.drop(rf_future_df.index[:7])\n",
    "\n",
    "# Rename Close to Predicted Close\n",
    "rf_future_df = rf_future_df.rename(columns={'Close': 'Predicted_Close'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82bdbba-7ac3-42ca-a232-2952427b202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(rf_future_df.head())\n",
    "display(rf_future_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14581d9c-83d1-4019-9826-386ecd5dcd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Historical and Predicted Stock Prices using Random Forest')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "\n",
    "# Plot the historical and predicted stock prices\n",
    "plt.plot(prices_df['Close'], label='Historical Prices')\n",
    "plt.plot(rf_future_df.index, rf_future_df['Predicted_Close'], label='Predicted Prices')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Save and show plot\n",
    "plt.savefig('rf_predict.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2eca02-e625-49e0-accd-120e6ce27c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print Importances from the Training data\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(X_train.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(X_train)\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(rf_model.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
